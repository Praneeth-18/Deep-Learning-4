{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/mBN4VNdIgDcf9Jrhrzac",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praneeth-18/Deep-Learning-4/blob/main/AI_Agents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **a) agent from scratch using tools in python**"
      ],
      "metadata": {
        "id": "Fr8gw-bF9ZFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "_NKDRYG1qHFB",
        "outputId": "5077bc7a-05c5-4d0a-e443-c803f9158c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.14.2\n",
            "    Uninstalling openai-1.14.2:\n",
            "      Successfully uninstalled openai-1.14.2\n",
            "Successfully installed openai-0.28.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              },
              "id": "9a1df53587354cab80f6eb602bfd92c7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylqMuIUImuj-",
        "outputId": "710414f2-05e1-446b-c12c-2753558f3221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Collecting openai\n",
            "  Using cached openai-1.14.2-py3-none-any.whl (262 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 0.28.0\n",
            "    Uninstalling openai-0.28.0:\n",
            "      Successfully uninstalled openai-0.28.0\n",
            "Successfully installed openai-1.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "print(openai.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJPA3PeUuvFV",
        "outputId": "44d034c2-2ac8-4ee5-edb4-a8f9e68f2c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve your OpenAI API key securely\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "api_key = api_key.strip()\n",
        "\n",
        "# Initialize the OpenAI client with the API key\n",
        "client = openai.OpenAI(api_key=openai.api_key)\n",
        "\n",
        "# Use the new method to create a chat completion\n",
        "chat_completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": \"Say this is a test\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print the response\n",
        "print(chat_completion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Zc_P_NvTIP",
        "outputId": "cb551e66-dcd9-4794-f449-a58414feca04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-96A2azWLvaCOlFczcB5suB47z85Jb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='This is a test.', role='assistant', function_call=None, tool_calls=None))], created=1711255592, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3bc1b5746c', usage=CompletionUsage(completion_tokens=5, prompt_tokens=12, total_tokens=17))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "class OpenAIChatBot:\n",
        "    def __init__(self, model=\"gpt-3.5-turbo\"):\n",
        "        \"\"\"\n",
        "        Initialize the chatbot with the specified model.\n",
        "        \"\"\"\n",
        "        # Ensure the OPENAI_API_KEY environment variable is set\n",
        "        self.api_key = userdata.get('OPENAI_API_KEY').strip()\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"OPENAI_API_KEY environment variable not set.\")\n",
        "\n",
        "        # Initialize the OpenAI client with the API key\n",
        "        self.client = openai.OpenAI(api_key=self.api_key)\n",
        "        self.model = model\n",
        "\n",
        "    def ask(self, user_message):\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": user_message}]\n",
        "        )\n",
        "        chat_response = response.choices[0].message.content  # Updated access method\n",
        "        return chat_response\n",
        "\n",
        "# Example usage remains the same\n",
        "\n",
        "\n",
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot = OpenAIChatBot()  # Initialize the chatbot\n",
        "    print(\"OpenAI ChatBot initialized. Ask me anything! Type 'exit' to stop.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        response = chatbot.ask(user_input)\n",
        "        print(\"Bot:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTWW5VRIysvj",
        "outputId": "6879d50a-abe2-4a87-feb9-8d5a6d308a0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI ChatBot initialized. Ask me anything! Type 'exit' to stop.\n",
            "You: what is 10+5\n",
            "Bot: 10 + 5 = 15\n",
            "You: teach me react\n",
            "Bot: Sure! React is a popular JavaScript library for building user interfaces. Here is a basic introduction to React:\n",
            "\n",
            "1. JSX: React uses JSX, which is a syntax extension for JavaScript that allows you to write HTML in your JavaScript code. JSX makes it easier to work with components and can help improve the readability of your code.\n",
            "\n",
            "2. Components: React is all about building reusable components that can be composed together to create complex user interfaces. Components are like custom HTML elements that you can use to structure your UI.\n",
            "\n",
            "3. State and Props: In React, data flows down from parent components to child components through props. Props are like function arguments that allow you to pass data and functions from a parent component to a child component. State is data that is managed within a component itself and can change over time.\n",
            "\n",
            "4. Lifecycle methods: React components have lifecycle methods that allow you to hook into various points in a component's lifecycle, such as when it is first mounted to the DOM or when it is about to be updated.\n",
            "\n",
            "Here is a simple example of a functional component in React:\n",
            "\n",
            "```jsx\n",
            "import React from 'react';\n",
            "\n",
            "const Greeting = ({ name }) => {\n",
            "  return <h1>Hello, {name}!</h1>;\n",
            "}\n",
            "\n",
            "export default Greeting;\n",
            "```\n",
            "\n",
            "In this example, we have a simple functional component called `Greeting` that takes a `name` prop and renders a greeting message using that prop.\n",
            "\n",
            "To use this component in another component, you would import it like so:\n",
            "\n",
            "```jsx\n",
            "import React from 'react';\n",
            "import Greeting from './Greeting';\n",
            "\n",
            "const App = () => {\n",
            "  return <Greeting name=\"John\" />;\n",
            "}\n",
            "\n",
            "export default App;\n",
            "```\n",
            "\n",
            "I hope this introduction helps you get started with React! There are many more features and concepts in React that you can explore, such as hooks, context API, and more. I recommend checking out the official React documentation for more in-depth information.\n",
            "You: thank you\n",
            "Bot: You're welcome! Let me know if you need help with anything else.\n",
            "You: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "class OpenAIChatBot:\n",
        "    def __init__(self, model=\"gpt-3.5-turbo\"):\n",
        "        \"\"\"\n",
        "        Initialize the chatbot with the specified model.\n",
        "        \"\"\"\n",
        "        # Fetch the OPENAI_API_KEY securely\n",
        "        self.api_key = userdata.get('OPENAI_API_KEY').strip()\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"OPENAI_API_KEY environment variable not set.\")\n",
        "\n",
        "        # Initialize the OpenAI client with the API key\n",
        "        self.client = openai.OpenAI(api_key=self.api_key)\n",
        "        self.model = model\n",
        "        self.chat_history = []  # Initialize the chat history\n",
        "\n",
        "    def ask(self, user_message):\n",
        "        \"\"\"\n",
        "        Directly sends a single message to the chat model and returns the response,\n",
        "        without altering the chat history.\n",
        "        \"\"\"\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": user_message}]\n",
        "        )\n",
        "        chat_response = response.choices[0].message.content\n",
        "        return chat_response\n",
        "\n",
        "    def start_chat(self):\n",
        "        \"\"\"Initialize or reset the chat history.\"\"\"\n",
        "        self.chat_history = []\n",
        "\n",
        "    def send_message(self, message):\n",
        "        \"\"\"\n",
        "        Send a message to the chat model and append the interaction to the chat history.\n",
        "        \"\"\"\n",
        "        self.chat_history.append({\"role\": \"user\", \"content\": message})\n",
        "        response = self.get_response()\n",
        "        print(\"Agent:\", response)\n",
        "\n",
        "    def get_response(self):\n",
        "        \"\"\"\n",
        "        Generate a response from the chat model based on the current chat history\n",
        "        and append the model's response to the chat history.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=self.chat_history\n",
        "            )\n",
        "            message_content = response.choices[0].message.content\n",
        "            self.chat_history.append({\"role\": \"assistant\", \"content\": message_content})\n",
        "            return message_content\n",
        "        except Exception as e:\n",
        "            return f\"An error occurred: {e}\"\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot = OpenAIChatBot()  # Initialize the chatbot\n",
        "    print(\"OpenAI ChatBot initialized. Ask me anything! Type 'exit' to stop.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        # Using send_message to leverage chat history\n",
        "        chatbot.send_message(user_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5kH0DsUzPxE",
        "outputId": "730e6f36-ff7e-4c4c-ef99-bbb625dee4b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI ChatBot initialized. Ask me anything! Type 'exit' to stop.\n",
            "You: what is 10x5x3\n",
            "Agent: 10 x 5 x 3 = 150\n",
            "You: what is react\n",
            "Agent: React is a JavaScript library developed by Facebook for building user interfaces. It allows developers to create interactive, dynamic, and fast web applications by using reusable UI components. React uses a component-based architecture and a virtual DOM to efficiently update and render components based on changes in the application state. It has gained popularity for its performance, flexibility, and simplicity in building modern web applications.\n",
            "You: how do we predict weather?\n",
            "Agent: Weather prediction involves the use of various tools, technologies, and scientific methods to forecast the future atmospheric conditions. Here are some of the key steps and factors involved in predicting weather:\n",
            "\n",
            "1. Data Collection: Meteorologists collect data from various sources, including weather stations, satellites, radar, and buoys. This data includes information on temperature, humidity, pressure, wind speed and direction, cloud cover, and precipitation.\n",
            "\n",
            "2. Numerical Weather Models: Meteorologists use sophisticated computer models that simulate the Earth's atmosphere based on mathematical equations. These models take into account the data collected and simulate how the atmosphere is likely to evolve over time.\n",
            "\n",
            "3. Observations and Analysis: Meteorologists analyze current weather conditions and compare them with the output of the numerical models to identify patterns and make predictions about future weather.\n",
            "\n",
            "4. Forecasting: Meteorologists generate weather forecasts based on the analysis of data and numerical models. These forecasts provide information on temperature, precipitation, wind patterns, and other atmospheric conditions for specific locations and time periods.\n",
            "\n",
            "5. Communication and Presentation: Weather forecasts are communicated to the public through various channels, including television, radio, websites, and mobile apps. Meteorologists use visual aids, maps, and charts to present the forecast in an easy-to-understand format.\n",
            "\n",
            "While weather prediction has improved significantly over the years, it is important to note that weather forecasts are still inherently uncertain due to the complexity of the Earth's atmosphere. Meteorologists use their expertise and experience to make educated predictions, but weather can still be unpredictable at times.\n",
            "You: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The updated version of the OpenAIChatBot class introduces several enhancements and additional functionalities compared to the earlier one, making it more versatile and suitable for a wider range of applications. Here's a breakdown of the improvements:\n",
        "\n",
        "1. Chat History Management\n",
        "Earlier Version: Did not explicitly manage or utilize chat history, making it less effective for conversations where context from previous messages is crucial.\n",
        "Updated Version: Introduces methods (start_chat, send_message, and get_response) to manage and utilize chat history. This allows the bot to maintain context over a conversation, leading to more coherent and contextually appropriate responses.\n",
        "2. Versatile Interaction Methods\n",
        "Earlier Version: Primarily focused on sending messages to the chat model without much flexibility in how interactions were handled.\n",
        "Updated Version: Offers two modes of interaction:\n",
        "Direct queries via the ask method for one-off questions without needing context.\n",
        "A conversational flow that leverages chat history for contextually rich interactions, suitable for more complex and ongoing conversations.\n",
        "3. Error Handling\n",
        "Earlier Version: Limited guidance on error handling within the provided snippets.\n",
        "Updated Version: The get_response method includes a try-except block, demonstrating a basic approach to handling potential exceptions that may occur during API calls. This makes the code more robust and provides a foundation for more comprehensive error handling strategies.\n",
        "4. Clear Structure and Extensibility\n",
        "Earlier Version: While functional, the class structure was more basic and focused on immediate functionality.\n",
        "Updated Version: The class is structured with clear responsibilities for each method, making it easier to understand, maintain, and extend. For instance, if new features or interaction patterns need to be added, the class's modular design facilitates these enhancements.\n",
        "5. Educational Value\n",
        "Updated Version: By introducing concepts like chat history management and different interaction modes, the updated version provides a richer example for learning about chatbot development and the possibilities offered by APIs like OpenAI's. It serves as a practical demonstration of managing state and context in conversational AI applications.\n",
        "Overall, the updated OpenAIChatBot class is a more comprehensive and flexible solution that better demonstrates how to build a chatbot capable of handling nuanced and contextually aware conversations. It lays a foundation for further development, potentially incorporating more advanced features such as sentiment analysis, personalized responses based on user history, or integration with other services and APIs."
      ],
      "metadata": {
        "id": "LHYUTCRYHjHO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rEXRRmTZ1afb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **b) demonstrations of various agent types with langchain**"
      ],
      "metadata": {
        "id": "fnrsySbh9gfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIZxVE_89xsZ",
        "outputId": "61e8c72e-a4d2-4eba-e781-4cbb97a273c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n",
            "  Downloading langchain_core-0.1.34-py3-none-any.whl (271 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.33-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.6/86.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m641.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.34 langchain-text-splitters-0.0.1 langsmith-0.1.33 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain"
      ],
      "metadata": {
        "id": "S4uLtilvE9XU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcu-yI-OcM3p",
        "outputId": "4610d9ab-a0fd-4387-aa7e-5109955a1a10"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/262.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m256.0/262.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdJvrr8Hceyz",
        "outputId": "7cb0de21-1960-4673-a500-c7bfbd6f2262"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=9573124e57db4016b349a8f4a7943804920af4adbfb562449164969cd2507fe3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Zero-shot ReAct**"
      ],
      "metadata": {
        "id": "1tHUTsLLdd-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from langchain.agents import initialize_agent, load_tools, AgentType\n",
        "from langchain.llms import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# Setup API key for OpenAI securely from Colab's stored user data\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY').strip()\n",
        "\n",
        "# Initialize the LLM with the retrieved API key\n",
        "lang_model = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# Load the necessary tools for the agent\n",
        "required_tools = load_tools([\"wikipedia\", \"llm-math\"], llm=lang_model)\n",
        "\n",
        "# Initialize the agent with a specific agent type and verbose mode enabled\n",
        "info_agent = initialize_agent(required_tools, lang_model, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# Execute two different runs to test the agent's response\n",
        "simple_math_result = info_agent.run(\"What is the sum of 4 and 5?\")\n",
        "addition_check_result = info_agent.run(\"Is it correct that 4 plus 5 equals 10?\")\n",
        "\n",
        "# Print the results obtained from the agent\n",
        "print(f\"Sum of 4 and 5: {simple_math_result}\")\n",
        "print(f\"Verification of 4 plus 5 equaling 10: {addition_check_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMRWPeSycK92",
        "outputId": "1ef7ae84-225a-4278-b9b7-f23574c4bea1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use the calculator tool to find the sum of numbers.\n",
            "Action: Calculator\n",
            "Action Input: 4 + 5\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 9\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
            "Final Answer: 9\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m This seems like a math question.\n",
            "Action: Calculator\n",
            "Action Input: 4+5\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 9\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Hmm, that doesn't seem right.\n",
            "Action: Calculator\n",
            "Action Input: 4+5\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 9\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Oh, I forgot to use the correct operator.\n",
            "Action: Calculator\n",
            "Action Input: 4*5\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 20\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Yes, that's correct!\n",
            "Final Answer: No, it is not correct. 4 plus 5 equals 9.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Sum of 4 and 5: 9\n",
            "Verification of 4 plus 5 equaling 10: No, it is not correct. 4 plus 5 equals 9.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conversational ReAct**"
      ],
      "metadata": {
        "id": "EItmmhktdi01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, load_tools\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve your OpenAI API key securely\n",
        "api_key = userdata.get('OPENAI_API_KEY').strip()\n",
        "\n",
        "# Initialize the language model with the API key\n",
        "language_model = OpenAI(openai_api_key=api_key)\n",
        "\n",
        "# Load the necessary tools for the agent\n",
        "agent_tools = load_tools([\"llm-math\"], llm=language_model)\n",
        "\n",
        "# Create a memory buffer for maintaining conversation history\n",
        "conversation_memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "\n",
        "# Instantiate a conversational agent with the tools and memory initialized above\n",
        "chat_agent = initialize_agent(\n",
        "    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
        "    tools=agent_tools,\n",
        "    llm=language_model,\n",
        "    verbose=True,  # Enable verbose to receive detailed logs\n",
        "    max_iterations=3,  # Set a maximum number of iterations for agent responses\n",
        "    memory=conversation_memory,\n",
        ")\n",
        "\n",
        "# Engage with the conversational agent and get responses to the prompts\n",
        "addition_query = chat_agent.run({\"input\": \"when you add 4 and 5 the result comes 10.\"})\n",
        "addition_result = chat_agent.run({\"input\": \"4 + 5 is \"})\n",
        "\n",
        "# Output the results from the conversational agent's interactions\n",
        "print(f\"Response to first prompt: {addition_query}\")\n",
        "print(f\"Response to second prompt: {addition_result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7oMgLK9dzRL",
        "outputId": "a7c1a785-abce-4027-8a1f-7ce95315ca23"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Calculator\n",
            "Action Input: 4 + 5\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 9\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: Yes, the result is 9. Did you input the numbers correctly?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
            "Action: Calculator\n",
            "Action Input: 4 + 5\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 9\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m Do I need to use a tool? No\n",
            "AI: Yes, you are correct. When you add 4 and 5, the result is 9. Good job!\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Response to first prompt: Yes, the result is 9. Did you input the numbers correctly?\n",
            "Response to second prompt: Yes, you are correct. When you add 4 and 5, the result is 9. Good job!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ReAct Docstore**"
      ],
      "metadata": {
        "id": "5gI7aR-Veiuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import Wikipedia\n",
        "from langchain.agents.react.base import DocstoreExplorer\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# Retrieve your OpenAI API key securely\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "api_key = api_key.strip()\n",
        "\n",
        "# Initialize the language model with your OpenAI API key securely retrieved from your environment\n",
        "llm = OpenAI(openai_api_key=api_key)\n",
        "\n",
        "# Assuming DocstoreExplorer is the correct way to interact with document stores, initialize it with Wikipedia\n",
        "docstore = DocstoreExplorer(Wikipedia())\n",
        "\n",
        "# Define the tools to be used by the react agent for search and lookup functionalities\n",
        "tools = [\n",
        "    Tool(name=\"Search\", func=docstore.search, description=\"Useful for when you need to ask with search\"),\n",
        "    Tool(name=\"Lookup\", func=docstore.lookup, description=\"Useful for when you need to ask with lookup\")\n",
        "]\n",
        "\n",
        "# Initialize the react agent with the specified tools and language model\n",
        "react_agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=\"react-docstore\"  # Ensure this agent type is correctly specified as per langchain's documentation\n",
        ")\n",
        "\n",
        "# Utilize the react agent to run search and lookup operations\n",
        "print(react_agent.run(\"Full name of Narendra Modi is Narendra Damodardas Modi?\"))  # Search operation\n",
        "print(react_agent.run(\"Full name of Narendra Modi is Narendra Damodardas Modi.\"))   # Lookup operation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADSQY5YcfXcS",
        "outputId": "365f99db-8d22-4f7b-c91d-cf0e7e0eaa3b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Narendra Damodardas Modi\n",
            "Narendra Damodardas Modi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Self-ask with Search**"
      ],
      "metadata": {
        "id": "cysFCtxMgziY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import Wikipedia\n",
        "\n",
        "# Retrieve your OpenAI API key securely\n",
        "api_key = userdata.get('OPENAI_API_KEY').strip()\n",
        "\n",
        "llm = OpenAI(openai_api_key=api_key)\n",
        "wikipedia_service = Wikipedia()\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Intermediate Answer\",\n",
        "        func=wikipedia_service.search,\n",
        "        description='Performs a Wikipedia search'\n",
        "    )\n",
        "]\n",
        "\n",
        "try:\n",
        "    agent = initialize_agent(\n",
        "        tools=tools,\n",
        "        llm=llm,\n",
        "        agent=\"self-ask-with-search\",\n",
        "        verbose=True,\n",
        "    )\n",
        "    result = agent.run(\"what is the capital of Japan?\")\n",
        "    print(result)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during agent execution: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VevmsVf4hPVY",
        "outputId": "894be398-e5a1-440e-ec71-b5f555f4652e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "An error occurred during agent execution: An output parsing error occurred. In order to pass this error back to the agent and have it try again, pass `handle_parsing_errors=True` to the AgentExecutor. This is the error: Could not parse output:  No, the question is clear and does not require any further clarification. The answer is: Tokyo.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nMXWlEcjlSVn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}